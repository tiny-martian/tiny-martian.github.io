# Haptic Motifs: Final Reflections

Wow... more than a year after beginning this project, it feels great to see all of the work I've done in this archive! 
During the time that I've worked on Haptic Motifs, I've researched a huge array of skills and disciplines.
From the right microphones to use for recording spatial audio, to the process Oculus went into when designing their controllers and their concept of hand presence, to the techniques often remniscent of sci-fi that creators can use to direct a viewer's attention around a 360 video, I've learned about some fascinating and detail-rich aspects of implementing great VR experiences that I never would have thought about before.
I've sweated over formatting scripts for interactive films, hunting down documentation from obscure Javascript functions, and uploading video from a certain 360 camera that really wanted to keep it for itself.
Thousands of words from progress blog updates and half of a script, stacks of academic papers, one week-long field trip, ten vibrating motors on a Velcro band, and many pivots later... I can look back on this project and all its ups and downs with pride.

In February 2019, I reached out to one of the many wonderful professors in my program, [Daniel Leithinger](http://www.leithinger.com/), asking him to sponsor my independent research project about combining haptic feedback with 360 video for improved user engagement. Daniel agreed to formally be my project mentor, and helped me craft [a proposal](https://docs.google.com/document/d/10u5PVBVAuj2Qi0cdqQ2EqBqLyPIk7T1ibRF5jVdosbo/edit?usp=sharing) for CU Boulder's UROP program that included the production of a short 360 film with an accompanying alternative controller, a UX study requiring IRB approval, and attendance at two conferences. The proposal was approved, and even won UROP's Savit Scholarship Award as an outstanding interdisciplinary proposal. Off to a great start!

The project didn't officially begin until the next August, when I made my [introductory progress blog post](./hmpp0.md). My official research question: "How can 360 video become more engaging to audiences through the use of nonconventional or alternative controller devices?" 

I spent the Fall 2019 semester researching attention guiding for immersive cinema and alternative controller design ([progress post 1](./hmpp1.md), [progress post 2](./hmpp2.md), [reading reviews](./hmrr.md), attending workshops and paper reviews at the 2019 International Conference on Interactive Digital Storytelling ([ICIDS review](./hmicids.md), and planning my 360 short film and accompanying controller ([progress post 3](./hmpp3.md), [progress post 4](./hmpp4.md).) For the latter, I decided after several great conversations with Daniel and other professional HCI researchers to build a programmable vibrating headband which could indicate the locations of points of interest around the user in 360 video scenes. The accompanying short film, "partyphantom", would provide motivation for the headband: set in a party being streamed with a 360 video camera, it would allow the user to overhear the thoughts of any partygoer who ventured near enough to the camera. The vibrating headband would indicate when characters had entered the camera's "telepathy range" and where they were located around the user, and ideally transform a chaotic, overwhelming situation into one involving meaningful decisions. Together, they would form an experience where social fear of missing out was mirrored by the fear of missing out on story content.

During the first two months of Spring 2020, everything was coming together! I was focusing on the rough draft of my [script](https://docs.google.com/document/d/1EkLE7u5HXZltYTpLwCjpztAlwNMmgrBoqJ7BYtkRlu4/edit?usp=sharing), exploring spatial audio recording techniques and starting to think about the code that would be involved, searching for actors, and planning my trip to South by Southwest 2020, where I would attend workshops, chat with creators in my field, and visit their awesome XR arcade. I met a new (and equally wonderful!) visiting professor from the University of Wyoming and VR researcher, [Amy Banic](http://www.uwyo.edu/cosc/cosc-directory/abanic/index.html), who helped mentor my project while Daniel was on parental leave. She encouraged me to attend the Boulder International Film Festival's XR pavilion, which featured a keynote speech by the lead directors of Disney Animation's Cycles, and helped me work through some initial prototypes of the headband. At the same time, I was beginning to explore haptics as tools for narrative engagement in cinematic XR more broadly as preparation for my senior capstone project ([case study!](https://docs.google.com/document/d/1DYNdV5aFa_ElzzqfPAxN3j14DIxeCL8B87GQLjYEYuQ/edit?usp=sharing))

And then, in late March, everything went south... although unfortunately not "by southwest". Within the span of about a week, my campus shut down, SXSW was cancelled, and my chances of shooting a 360 short film with live actors were dramatically reduced. However, Daniel and Amy made it possible for me to continue working on the technical side of the project by helping me get supplies to work with at home and Zooming with me weekly to check in on my progress. Between the Sparkful order that they set up for me and my dad's workbench, I was able to build a working prototype of the programmable headband ([progress post 5], [progress post 6]) and start connecting it to Arduino and Unity. I also spent some time working on my [360 cinematography skills](https://lilliebahrami.com/360-violin-performance).

The semester wrapped up, and my UROP grant was officially over. However, over the previous few months, I had become increasingly interested in browser-based VR and using haptics as an imaginative, rather than a utilitarian, story resource. Amy and Daniel agreed to keep meeting with me over the summer while I experimented with moving the project away from Unity and into A-frame, using the Chrome Web Serial API to bridge the gap between the Arduino and the browser ([progress post 7], [progress post 8]). While I ran out of steam on this stage of the project and had to confront my lack of Javascript knowledge, this was still a very cool addition and gave me a great introduction to 360 video controls in A-frame and serial communication from the browser.


