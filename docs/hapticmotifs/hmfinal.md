# Haptic Motifs: Final Reflections

Wow... more than a year after beginning this project, it feels great to see all of the work I've done in this archive! 
During the time that I've worked on Haptic Motifs, I've researched a huge array of skills and disciplines.
From the right microphones to use for recording spatial audio, to the process Oculus went into when designing their controllers and their concept of hand presence, to the techniques often remniscent of sci-fi that creators can use to direct a viewer's attention around a 360 video, I've learned about some fascinating and detail-rich aspects of implementing great VR experiences that I never would have thought about before.
I've sweated over formatting scripts for interactive films, hunting down documentation from obscure Javascript functions, and uploading video from a certain 360 camera that really wanted to keep it for itself.
Thousands of words from progress blog updates and half of a script, stacks of academic papers, one week-long field trip, ten vibrating motors on a Velcro band, and many pivots later... I can look back on this project and all its ups and downs with pride.

In February 2019, I reached out to one of the many wonderful professors in my program, [Daniel Leithinger](http://www.leithinger.com/), asking him to sponsor my independent research project about combining haptic feedback with 360 video for improved user engagement. Daniel agreed to formally be my project mentor, and helped me craft [a proposal](https://docs.google.com/document/d/10u5PVBVAuj2Qi0cdqQ2EqBqLyPIk7T1ibRF5jVdosbo/edit?usp=sharing) for CU Boulder's UROP program that included the production of a short 360 film with an accompanying alternative controller, a UX study requiring IRB approval, and attendance at two conferences. The proposal was approved, and even won UROP's Savit Scholarship Award as an outstanding interdisciplinary proposal. Off to a great start!

The project didn't officially begin until the next August, when I made my [introductory progress blog post](./hmpp0.md). My official research question: "How can 360 video become more engaging to audiences through the use of nonconventional or alternative controller devices?" 

I spent the Fall 2019 semester researching attention guiding for immersive cinema and alternative controller design ([progress post 1](./hmpp1.md), [progress post 2](./hmpp2.md), [reading reviews](./hmrr.md), attending the 2019 International Conference on Interactive Digital Storytelling ([ICIDS review](./hmicids.md), and planning my 360 short film and accompanying controller ([progress post 3](./hmpp3.md), [progress post 4](./hmpp4.md).) For the latter, I decided after several great conversations with Daniel and other professional HCI researchers to build a programmable vibrating headband which could indicate the locations of points of interest around the user in 360 video scenes. The accompanying short film, "partyphantom", would provide motivation for the headband: set in a party being streamed with a 360 video camera, it would allow the user to overhear the thoughts of any partygoer who ventured near enough to the camera. The vibrating headband would indicate when characters had entered the camera's "telepathy range" and where they were located around the user, and ideally transform a chaotic, overwhelming situation into one involving meaningful decisions. Together, they would form an experience where social fear of missing out was mirrored by the fear of missing out on story content.


